\section{Analysis and Opportunities of a Video Streaming Architecture}
\label{sec:system-archi}

%{\color{blue} This section explains the architecture system, and what it is  for, explaining some protocols flowcharts. Studying the protocols and focusing in the system part of the experiments.}

%This section explains the modeling used in our experiments. We first provide an overview of the proposed video streaming service impacts in multi-tier networks. The remaining subsections describe the implementation of this service architecture.
Designing a cache hierarchy on vertically organized edge nodes with N tiers presents some improvements in users’ QoE. The before-mentioned architecture can achieve such advantages by serving the requested content as close as possible to the user. So that efficiently forwarding requests between parent edge nodes within the hierarchy, balancing the video traffic in terms of hop counts and users attended. In addition, the network core congestion is reduced since it represents an operational overhead for the content provider.
As a preliminary outcome achieved by a multi-tier network experiment, the QoE impact over a video streaming service is assessed. Thereafter, we describe some facts about the QoE characteristics and insights on the opportunities of caching multimedia content in edge nodes of multi-tier networks.

\subsection{Impact of Fog Multi-tier Network Approach}

To confirm these differences in users' performance requesting a video from cache nodes in different tiers, we present two users requesting multimedia content in different layers. Then an analysis of the impacts over the network is addressed. The Figure~\ref{fig:impact-two-layers} illustrates a two-tier network model. The graphs show the results of bitrate, interruptions, buffer and representations switch, respectively, from left to right.%and along x-axis the simulation time. 
When a client requests a cache edge node video, it can be located in layer L1 or L2. Each layer level has different network factors, e.g., load, latency, so on. Accordingly, the Figure~\ref{fig:multi-tier-network}, an L1 layer can be interpreted as a personal computer, laptops, and smartphones, where the node transmits the video content through wired or wireless communication. Whereas in the L2 layer, a specific Edge gateway can be distributed on local edge nodes.

\begin{figure*}
    \centering
    \includegraphics[width=0.65\linewidth]{images/qoe-multi-level.pdf}
    \caption{\textbf{The number of bitrate switches, stalls, buffer size, the startup delay in seconds of a DASH player requesting a video with 10 bitrate levels varying from 50 to 4,500Kbps and from nodes in different tiers.}}
    \label{fig:impact-two-layers}
\end{figure*}


As we can see, besides the initial interruption until the start of the video, both users have had no interruptions during the video execution. However, the user who received the video on the nearest edge layer had a higher bit rate than the other user. 
Note that the closest user could fill the buffer faster, and thus, he managed to keep the video playing at the best possible resolution.
Whereas the user who received the video from a distant layer, in some moments, worked with the buffer at the limit and had to constantly switch resolutions so that there is no interruption during the video execution. 
Both users received the same video from different Layers. Even without any interruptions in both video playbacks, the transmission from different tiers directly impacts the users' QoE.


\subsection{Multi-tier Edge-Cloud Network Opportunities}

%Esta seção apresenta algumas oportunidades dentro de redes multi-tier edge/cloud para o provisionamento da transmissção de videos. Aproveitar nós próximos aos usuários podem melhorar o funcionamento do rede como um todo, aqui nós discutimos alguns insights que podem ser usados em favor dos stakeholders que utilizam a infraestrutura para transmissão de video. 
The opportunities within multi-tier edge/cloud networks for the provision of video transmission are presented below. The advantages of nodes closer to end-users can improve the functioning of the network as a whole, here we discuss some insights that can be used in favor of network and provider admin in the infrastructure for video transmission.

\subsubsection{Improving User QoE}

%the cloud distributes the video content to the different levels of the edge. Depending the level which the video is cached the users' experience changes. The architecture is based on held the video distribution with QoE support. The work divides the edge into three layers, to guarantee coverage, storage, upload and download capacity. 
Inside a multi-tier environment composed of more than one domain of devices, the domain resources can host the video content near the end-users, reducing latency and mitigating the load on the network's core. The edge nodes are composed of specific resources combined to carry out the video transmission to integrate video streaming services in such communication environments. Within this context, mechanisms for integrating schemes and video streaming raise as an opportunity to improve QoE.% at each network level.
The results reported in Fig~\ref{fig:impact-two-layers} shows that it is possible to improve the users' satisfaction using the edge multi-tier network. Depending on the level of allocation of the video service, the video smoothing variation between characteristics of the player changes.


\subsubsection{Potential Bandwith Saving}

%Video Caching, Analytics, and Delivery at the Wireless Edge: A Survey and Future Directions
Videos streamed in higher quality increase network bandwidth. Consequently, provisioning from the Cloud will incur high communication expenses. 
The process of delivering part of the video along the network can significantly save bandwidth utilization instead of sending the entire video to an edge server or by lowering the encoding quality of uninteresting portions of the video. Different delivery approaches can have different performances to reduce the uplink bandwidth. Moreover, none of the surveyed articles have considered the end-to-end design of video streaming, wherein the edge server adapts the video streams based on uplink and downlink bandwidth capacities. Additionally, new forms of video content are being generated today.


\subsubsection{Cacheability}

%Caching audio/video during peak hours ...
%Manage the QoE users refer to those services where the Controller can centrally control the satisfaction guarantees. The Controller can address this problem by creating a control channel to managed-quality video streaming services over the edge-cloud network.

In the edge network, the nodes located at the edge are responsible for providing resources to VoD providers to allocate their caches. 
Notice that the caches are to multi-hop away from the content provider/consumer. 
With new possibilities being created to offer better services that work on the internet. As the problem becomes complex and new challenges arise to be solved. Different characteristics have to be studied in multi-tier environments into the edge, such as cache allocation, placement, replacement, and selection caches, usually making real-time decisions. In addition, each content can be split dynamically in a set of pieces to serve the end-users, taking into account different regards, such as the mobility presented by the user and the possibility of predicting the moving directing. 

