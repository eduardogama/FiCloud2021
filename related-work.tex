\section{Motivation and Related Work}
\label{sec:related-work}

This section describes the related works in edge/cloud computing for video streaming. Here, some representative works in QoE are summarized regarding the edge network topologies and their impacts on video provisioning.

%CACA: Learning-based Content-aware Cache Admission for Video Content in Edge Caching
In Guan~\textit{et al.}~\cite{guan:2019:CLC} demonstrate the performance of the two-tier edge caching network. This work developed an algorithm to reach a 15\% of hit ratio in multimedia content consuming 20\% less memory usage. They deployed a video caching system. When a user requests a video, the address IP mapping redirects the request to the nearest cache.
If the cache node does not hit the video, the edge node forwards it to the upper tier, which in turn forwards the request to the upper tier until it reaches the source. Otherwise, on any node storing the video in a cache, it will return immediately, and the current node will not forward the request to an upper tier.

Rosario~\textit{et al.}~\cite{rosarioSENSORS2018} present an architecture for virtual machine migration in real-time. During the migration, the video provisioning is moved forward over a multi-tier network. The architecture is based on the SDN paradigm for video distribution with QoE support. The work divides the edge into three tiers to ensure storage, upload and download capacity as presented in~\ref{fig:multi-tier-network}. In the experimental scenario, the cloud distributes the video content to the different edge levels with the multimedia service.

In Shen~\textit{et al.}~\cite{shenIWQoS19} works with a set of cache proxy services to analyze the cache miss occurrences. This work implements a reactive approach where cache proxies download the chunks of multimedia content when requested. The cache services use probability theory to improve the efficiency of transferring corresponding video segments in the cloud. In this way, they demonstrated an improvement in the users' QoE.

%Layered Hierarchical Caching for SVC-Based HTTP Adaptive Streaming over C-RAN
In Zhang~\textit{et al.}~\cite{zhang:WCNC2017}, the network consists of a cloud server connected to a pool of baseband units and a set of remote radio heads as cache nodes. The environment is organized hierarchically in multiple layers, where the proposed heuristic is formulated to consider the download rate between the nodes in the cache. The solution has two objectives: to minimize the amount of backhaul traffic and to improve the hit rate in VoD systems

Bentaleb~\textit{et al.}~\cite{bentaleb:2018:MSys} develop a Game Theory Algorithm (GTA), a new customer-oriented scheme whithin client-side that seeks to select the best bitrate. Unlike most works in DASH Multimedia Systems, in which users strive to maximize the QoE of the viewer without considering other entities on the network, this solution allows efficient collaboration between different player entities. The GTA improves the users' QoE with emphasis on the perceptual quality of the viewer, without explicit communication overload, respecting the decision requirements of the existing players. In addition, this work considers the cross-traffic in different network conditions.

%In this project we aim to design a video delivery system that considers such issues to improve quality of experience for a range of video streaming needs, including low latency requirements.
The approaches above could decrease the traffic load and improve QoE. However, more issues arise in such dynamic scenarios: user mobility, collaborative cache services over multi-edge, users' number during flash crowds, and interactive streaming requirements are not fully considered.  Proper management and orchestration of video delivery over the Internet is core to the smooth coexistence of heterogeneous video services. This work focus on edge/cloud hierarchy to show the impacts of video streaming services in a multi-tier environment, as well as the need to have a real-time video streaming orchestration.

%The aforementioned approaches could decrease the traffic load and improve QoE, but more
%issues arise in such scenarios: user mobility, collaborative cache schemes over multi-edge, the amount of users during flash crowds, and interactive streaming requirements are not fully considered. In this project we aim to design a video delivery system that considers such issues to improve quality of experience for a range of video streaming needs, including low latency requirements.
%
%
%The aforementioned approaches could decrease the traffic load and improve QoE, but more
%issues arise in such scenarios: user mobility, collaborative cache schemes over multi-edge, the amount of users during flash crowds, and interactive streaming requirements are not fully considered. In this project we aim to design a video delivery system that considers such issues to improve quality of experience for a range of video streaming needs, including low latency requirements.